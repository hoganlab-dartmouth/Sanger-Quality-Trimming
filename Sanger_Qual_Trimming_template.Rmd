---
title: "Sanger Quality Trimming"
author: "Jay Goddard"
date: "2024-07-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Section 1: Objective

Goal here is to make a medium-throughput workflow to take the tsv files, exported from Snapgene on absorbance trace files (with quality scores shown) into an R dataframe. 
Visualization of sequences and respective quality scores will then allow for read-trimming selection for each read, while holding only information regarding the 5' trimmed length.

Following conversion of these trimmed reads into a multi-fasta file, said sanger reads file can be aligned against the relevant strain genome using MUMer's nucmer/show-coords functions, or re-uploaded to Snapgene for alignment with higher confidence than Snapgene's default filtering thresholds.


## Section 2: Function Modules

Run the three below code chunks prior to any data analysis. Once loaded, workflow is:

1. Import sanger read tsv file(s)

2. Run imported tsv file through `roll_avg_calc`

3. Run imported tsv file (now including the 20bp rolling avg calculations on quality scores) through `roll_avg_plot`

4. In new window that opens, select position in sanger read to "start" the trimmed read sequence at (aiming for minimum phred=3-, but may need to accept phred=20 to realistically use certain lower quality reads)

5. Run `read_trimming`, providing the read's sample name, the same imported tsv that has been modified by the above functions, and the bp coordinate where the new trimmed read's 5' end should start. This function will export a csv file for this sample, and the dataframe.


When running step 5, note that, when running samples individually (or through a for loop, as planned for this sample set) the temporary dataframe generated by `read_trimming` to make the export csv can also be saved with a new dataframe name, if one wishes to merge all sample trimmed read dataframes in R as opposed to excel processing.

```{r quality_analysis_module}
#note that "input_tsv" argument is each sanger sequence read's imported tsv file containing sequence and phred scores
roll_avg_calc <- function(sample_name, input_tsv){

input_tsv$Qual_Roll_Avg = NA
for (i in 10:(nrow(input_tsv)-10)){
  input_tsv$Qual_Roll_Avg[i] <- mean(input_tsv$Quality.Score[(i-10):(i+10)])
}
assign(paste0(sample_name, "_output_df"), input_tsv, envir=.GlobalEnv)
}
```


```{r graphing_module}
library(shiny)
library(ggplot2)
library(plotly)

roll_avg_plot <- function(sample_name,inp_df){
ylabel_list <- c(5,10,15,20,25,30,35,40,45,50,55,60,65,70,75)
xax_list <- c()
n=1
for (i in 5:10000){
  if(i%%25 == 0){
    xax_list[n] <- i
    n=n+1
  }
}
  
ui <- fluidPage(
    plotlyOutput("distPlot")
)

server <- function(input, output) {
   output$distPlot <- renderPlotly({
      ggplot(inp_df, aes(x=Position, y=Qual_Roll_Avg, ylab=5)) + geom_point() + geom_hline(yintercept=20) + geom_hline(yintercept=30) + scale_y_continuous(breaks=ylabel_list, labels=ylabel_list) + scale_x_continuous(breaks=xax_list, labels=xax_list)
     })
}
shinyApp(ui = ui, server = server)
}
```

Running the above graphing function `roll_avg_plot` on the dataframe produced by `roll_avg_calc` will generate a new window, where you can interactive with individual data point rolling average quality scores, and select an "exact" bp to cut-off at, without requiring manipulation of the plot axes for each new sanger sequence read dataframe. 

The function `read_trimming`` in the below code chunk will require the dataframe and the coordinate you have chosen to begin the trimmed sanger sequence read at. This includes both 5' only trimming, and trimming of low quality sequences from both 5' and 3' of read.


```{r trimming_module}
library(readr)
library(stringr)
read_trimming <- function(sample_name,input_tsv,input_coord1, input_coord2){
#first, code for converting dataframe column into string
full_seq <- paste(input_tsv$Base.Call[], collapse="")
full_length <- nchar(full_seq)
trimmed_5 <- input_coord1
trimmed_seq <- paste(input_tsv$Base.Call[input_coord1:nrow(input_tsv)], collapse="")
trimmed_seq2 <- paste(input_tsv$Base.Call[input_coord1:input_coord2], collapse="")
trimmed_length <- (nchar(full_seq) - nchar(trimmed_seq))
trimmed_length2 <- (nchar(full_seq) - nchar(trimmed_seq2))
N_content <- str_count(trimmed_seq2, "N")
N_percent <- N_content/(nchar(trimmed_seq2))

export_df <- data.frame(
  Sample = sample_name,
  Sequence = full_seq,
  Sequence_Length = full_length,
  Trim_5_Length = trimmed_5,
  Trimmed_Sequence_5 = trimmed_seq,
  Trimmed_Sequence = trimmed_seq2,
  Trimmed_5_Seq_Length = trimmed_length,
  Trimmed_Seq_Length = trimmed_length2,
  Trimmed_N_Content = N_content,
  Trimmed_N_Percent = N_percent
)
assign(paste0(sample_name, "_export_df"), export_df, envir=.GlobalEnv)

write_delim(export_df, paste0("<path-to-sequences>", sample_name, "_trimmed.csv"), delim=",")
}
```



## Actual Sample Workflow

### Full FastQ and TSV import

Will now import tsv files containing sanger sequence read and associated bp phred scores, to run through the three below functions, and select final trimmed sequence to assemble as multi-fasta for next step (alignment against genome).

To reiterate, a sanger read's ab1 file can be opened in Snapgene and exported as a tsv to convert the features within that spectra file into a usable table.

Plan is initial cut-off phred=30 (ie. I will not take stop trimming until the 20bp rolling avg comes above 30), but will allow middle-sequence and tailing lower quality, while hoping to keep at or above phred=20.

```{r tools_import}
setwd("<path-to-sequences>")
phred_ascii_conv <- read.csv("./phred_ascii_conversion_20240626.csv")
#<strain-to-file_name labels import>
strain_to_file <- read.csv("./strain_to_file_labels.csv")
#for loop or manual entry of all tsv files converted from ab1 files, ensuring data is properly assigned to sample throughout workflow
```



### Workflow/Sample Processing

Example code-chunk template, for copying/pasting and use with each individual sanger read file.

```{r data_analysis_template}
#Do not run this as a chunk. Run each line individually (trying to run graphing module and more lines below prevents graph generation, and coordinates in read_trimming function require manual coordinates selected from graph)
setwd("<location-of-sanger-files>") #already set above, but reiterating, and providing here in case you have files in multiple locations


#list and loop for importing all files in directory as individual dataframes with same names as original files
files_to_read1 <- list.files("./<subdirectory, if relevant. remove this argument entirely if all samples are in one dorectory>/", pattern = "*.tsv") 
#files_to_read2 <- list.files("./", recursive = TRUE, pattern = "*.tsv") 
#Adding recursive = FALSE argument to above list.files() function, as seen in commented out `files_to_read2` object, would allow for pulling all files from subdirectories at once- will employ that usage on full sanger reads dataset against J215 polished genome, once that draft assembly has been closed to a single contig and annotated w/PAO1 and PA14 genes
for(file in files_to_read1){
  name <- paste(file)
  name <- assign(name, read.delim2(paste0("./<subdirectory, if relevant. remove this argument entirely if all samples are in one dorectory>/",file)))
}

#run these next three lines only once. They are for combining individual full/trimmed sequences to single dataframe. Running again in between samples will overwrite existing dataframe
export_cols <- c("Sample", "Sequence", "Sequence_Length", "Trim_5_Length", "Trimmed_Sequence_5", "Trimmed_Sequence", "Trimmed_Length_5", "Trimmed_Length", "Trimmed_N_Content", "Trimmed_N_Percent")
trimmed_df = data.frame(matrix(nrow=0,ncol=length(export_cols)))
colnames(trimmed_df) <- export_cols 


XXX_XXX_tsv <- read.delim2("./189829_G07_026.tsv") #example import of 1 file

#for easier entry of all four functions, without accidental typos from sample to sample...
in1 <- XXX_XXX_tsv #if using for loop above, will need to use full file name that was imported as dataframe label
sname <- "XXX_XXX_YYYYMMDDname"

roll_avg_calc(sname, in1)

out1 <- data.frame(mget(paste0(sname,"_output_df")))
colnames(out1) <- c("Position","Base.Call","Quality.Score","A.Value","C.Value","G.Value","T.Value","Qual_Roll_Avg")

roll_avg_plot(sname, out1)
#for this sanger read, define start and end coordinates from above graph for trimming
start1 <- #
end1 <- #

read_trimming(sname, in1, start1, end1)

trimmed_df <- (rbind(trimmed_df, get(paste0(sname, "_export_df")))) #perform this in between each sample, to gather all raw/trimmed sequences into single dataframe for export

#and now, having gathered all original/trimmed sequences into one dataframe, time for multifasta export...

trimmed_export_df <- trimmed_df %>% 
  unite(col="Read_ID", c("Sample", "Trim_5_Length", "Trimmed_Seq_Length", "Trimmed_N_Content", "Trimmed_N_Percent"), sep="|")
trimmed_export2_df<- trimmed_export_df[,c("Read_ID","Trimmed_Sequence")]
trimmed_export2_df$Read_ID <- paste0(">",trimmed_export2_df$Read_ID) 

write.table(trimmed_export2_df, "/trimmed_sequences/<sample-batch-name>_trimmed.fasta", quote=FALSE, sep="\n", col.names = FALSE, row.names = FALSE)
```



## Next Steps

From here, all exported csv's can be merged in excel, saved as a text file, and formatting converted into multi-fasta sequence (with sequence name AND 5' trimmed length in sample/"contig" name, for usage in future steps). 

Alternatively (as shown above in this document), the data exported as individual csv files can also be gathered into a single dataframe and exported as a multi-fasta within R.

This multi-fasta will be run through MUMmer's nucmer/show-coords functions against the relevant genome to locate transposon insertion sites, or re-uploaded into Snapgene for manual alignment using the trimmed sequences.